use anyhow::{anyhow, Result};

use crate::utils::{Scale01, Scale22};

struct OpenAI {
    model_name: OpenAIModels,
    /// Temperature is used to control the randomness or creativity
    /// of the model's output. Temperature is a parameter that affects
    /// the distribution of probabilities generated by the model.
    temperature: f64,
    /// Limits the length of the generated output
    max_tokens: u64,
    /// With top_p (probabilistic sampling), the model considers only the most
    /// likely words whose cumulative probability exceeds a specified threshold.
    /// This threshold is determined by the top_p parameter, which is typically
    /// set between 0 and 1.
    ///
    /// A lower value, such as 0.1 or 0.3, restricts the sampling to a
    /// narrower range of high-probability words. This leads to
    /// more focused and deterministic output, with fewer alternatives
    /// and reduced randomness.
    top_p: Scale01,
    /// The frequency penalty parameter helps reduce the repetition of words
    /// or sentences within the generated text. It is a float value ranging
    /// from -2.0 to 2.0, which is subtracted to the logarithmic probability of a
    /// token whenever it appears in the output. By increasing the
    /// frequency penalty value, the model becomes more cautious and less likely
    /// to use repeated tokens frequently.
    ///
    /// In the official documentation:
    /// https://platform.openai.com/docs/api-reference/chat/create#chat/create-frequency_penalty
    frequency_penalty: Scale22,
    // presence
}

enum OpenAIModels {
    DaVinci003,
}
