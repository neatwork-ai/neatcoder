use anyhow::Result;
use serde::Serialize;
use std::collections::HashMap;

use crate::{
    models::Models,
    utils::{Bounded, BoundedFloat, Scale01, Scale100s, Scale22},
};

#[derive(Debug, Serialize, Clone)]
pub struct ChatParams {
    pub model: Models,
    // TODO: THIS SHOULD BE Scale02
    /// Temperature is used to control the randomness or creativity
    /// of the model's output. Temperature is a parameter that affects
    /// the distribution of probabilities generated by the model.
    ///
    /// When the temperature is set to its mininmum, the sampling mechanism converges
    /// to greedy decoding, in other words the token stream will be deterministic
    pub temperature: Option<f64>,
    /// Limits the length of the generated output.
    /// If `None` it defaults to `Inf`
    pub max_tokens: Option<u64>,
    /// With top_p (probabilistic sampling), the model considers only the most
    /// likely words whose cumulative probability exceeds a specified threshold.
    /// This threshold is determined by the top_p parameter, which is typically
    /// set between 0 and 1.
    ///
    /// A lower value, such as 0.1 or 0.3, restricts the sampling to a
    /// narrower range of high-probability words. This leads to
    /// more focused and deterministic output, with fewer alternatives
    /// and reduced randomness.
    pub top_p: Option<Scale01>, // TODO: Add getter
    /// The frequency penalty parameter helps reduce the repetition of words
    /// or sentences within the generated text. It is a float value ranging
    /// from -2.0 to 2.0, which is subtracted to the logarithmic probability of a
    /// token whenever it appears in the output. By increasing the
    /// frequency penalty value, the model becomes more cautious and less likely
    /// to use repeated tokens frequently.
    ///
    /// In the official documentation:
    /// https://platform.openai.com/docs/api-reference/chat/create#chat/create-frequency_penalty
    pub frequency_penalty: Option<Scale22>, // TODO: Add getter
    /// The presence penalty parameter stears how the model penalizes new tokens
    /// based on whether they have appeared (hence presense) in the text so far.
    ///
    /// The key difference between this param and the frequency param is that the
    /// `presence` penalty is not really concern with the frequency itself.
    ///
    /// In the official documentation:
    /// https://platform.openai.com/docs/api-reference/chat/create#chat/create-presence_penalty
    pub presence_penalty: Option<Scale22>, // TODO: Add getter
    /// How many chat completion choices to generate for each input message.
    pub n: Option<u64>,
    /// Whether to stream back partial progress. If set, tokens will be sent as
    /// data-only server-sent events as they become available, with the stream
    /// terminated by a data: [DONE] message.
    pub stream: bool,
    /// Modify the likelihood of specified tokens appearing in the completion.
    ///
    /// Accepts a json object that maps tokens (specified by their token ID
    /// in the tokenizer) to an associated bias value from -100 to 100.
    /// Mathematically, the bias is added to the logits generated by the model
    /// prior to sampling. The exact effect will vary per model, but values
    /// between -1 and 1 should decrease or increase likelihood of selection;
    /// values like -100 or 100 should result in a ban or exclusive selection
    /// of the relevant token.
    pub logit_bias: HashMap<String, Scale100s>, // TODO: Add getter
    /// A unique identifier representing the end-user, which can help OpenAI
    /// to monitor and detect abuse. You can read more at:
    /// https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids
    pub user: Option<String>,
}

impl ChatParams {
    pub fn new(
        model: Models,
        temperature: Option<f64>,
        max_tokens: Option<u64>,
        top_p: Option<f64>,
        frequency_penalty: Option<f64>,
        presence_penalty: Option<f64>,
        n: Option<u64>,
        stream: bool,
        logit_bias: HashMap<String, Scale100s>,
        user: Option<String>,
    ) -> Result<ChatParams> {
        let top_p = match top_p {
            Some(top_p) => Some(BoundedFloat::new(top_p)?),
            None => None,
        };

        let frequency_penalty = match frequency_penalty {
            Some(frequency_penalty) => {
                Some(BoundedFloat::new(frequency_penalty)?)
            }
            None => None,
        };

        let presence_penalty = match presence_penalty {
            Some(presence_penalty) => {
                Some(BoundedFloat::new(presence_penalty)?)
            }
            None => None,
        };

        Ok(Self {
            model,
            temperature,
            max_tokens,
            top_p,
            frequency_penalty,
            presence_penalty,
            n,
            stream,
            logit_bias,
            user,
        })
    }

    pub fn empty(model: Models) -> Self {
        Self {
            model,
            temperature: None,
            max_tokens: None,
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            n: None,
            stream: false,
            logit_bias: HashMap::new(),
            user: None,
        }
    }

    // === Setter methods with chaining ===

    pub fn logit_bias(
        mut self,
        logit_bias: HashMap<String, Scale100s>,
    ) -> Result<ChatParams> {
        self.logit_bias = logit_bias;
        Ok(self)
    }
}

impl ChatParams {
    // === Setter methods with chaining ===
    pub fn top_p(mut self, top_p: f64) -> Self {
        self.top_p = Some(Scale01::new(top_p).expect("Invalid top_p value"));
        self
    }

    pub fn max_tokens(mut self, max_tokens: u64) -> Self {
        self.max_tokens = Some(max_tokens);
        self
    }

    pub fn frequency_penalty(mut self, frequency_penalty: f64) -> Self {
        self.frequency_penalty = Some(
            Scale22::new(frequency_penalty).expect("Invalid frequency penalty"),
        );
        self
    }

    pub fn presence_penalty(mut self, presence_penalty: f64) -> Self {
        self.presence_penalty = Some(
            Scale22::new(presence_penalty).expect("Invalid presence penalty"),
        );
        self
    }

    pub fn user(mut self, user: String) -> Self {
        self.user = Some(user);
        self
    }

    pub fn default_with_model(model: Models) -> Self {
        Self {
            model,
            temperature: None,
            max_tokens: None,
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            n: None,
            stream: false,
            logit_bias: HashMap::new(),
            user: None,
        }
    }
}

// ==== WASM ====

#[cfg(feature = "wasm")]
pub mod wasm {
    use std::ops::{Deref, DerefMut};

    use super::*;

    use wasm_bindgen::{prelude::wasm_bindgen, JsValue};
    use wasmer::{jsvalue_to_hmap, JsError};

    #[wasm_bindgen(js_name = "ChatParams")]
    pub struct ChatParamsWasm(ChatParams);

    #[wasm_bindgen]
    impl ChatParamsWasm {
        #[wasm_bindgen(constructor)]
        pub fn new(
            model: Models,
            temperature: Option<f64>,
            max_tokens: Option<u64>,
            top_p: Option<f64>,
            frequency_penalty: Option<f64>,
            presence_penalty: Option<f64>,
            n: Option<u64>,
            stream: bool,
            logit_bias: JsValue,
            user: Option<String>,
        ) -> Result<ChatParamsWasm, JsError> {
            let mut logit_bias = jsvalue_to_hmap(logit_bias)?;

            let params = ChatParamsWasm(
                ChatParams::new(
                    model,
                    temperature,
                    max_tokens,
                    top_p,
                    frequency_penalty,
                    presence_penalty,
                    n,
                    stream,
                    logit_bias,
                    user,
                )
                .map_err(|e| JsError::from_str(&e.to_string()))?,
            );

            Ok(params)
        }

        #[wasm_bindgen]
        pub fn empty(model: Models) -> Self {
            ChatParamsWasm(ChatParams::empty(model))
        }

        #[wasm_bindgen(js_name = logitBias)]
        pub fn logit_bias(
            mut self,
            logit_bias: JsValue,
        ) -> Result<ChatParamsWasm, JsError> {
            let mut logit_bias = jsvalue_to_hmap(logit_bias)?;

            let logit_bias = logit_bias
                .drain()
                .map(|(key, val)| Ok((key, Scale100s::new(val)?)))
                .collect::<Result<HashMap<String, Scale100s>>>()
                .map_err(|e| JsError::from_str(&e.to_string()))?;

            self.logit_bias = logit_bias;
            Ok(self)
        }

        #[wasm_bindgen(js_name = topP)]
        pub fn top_p(mut self, top_p: f64) -> Self {
            self.top_p =
                Some(Scale01::new(top_p).expect("Invalid top_p value"));
            self
        }

        #[wasm_bindgen(js_name = maxTokens)]
        pub fn max_tokens(mut self, max_tokens: u64) -> Self {
            self.max_tokens = Some(max_tokens);
            self
        }

        #[wasm_bindgen(js_name = frequencyPenalty)]
        pub fn frequency_penalty(mut self, frequency_penalty: f64) -> Self {
            self.frequency_penalty = Some(
                Scale22::new(frequency_penalty)
                    .expect("Invalid frequency penalty"),
            );
            self
        }

        #[wasm_bindgen(js_name = presencePenalty)]
        pub fn presence_penalty(mut self, presence_penalty: f64) -> Self {
            self.presence_penalty = Some(
                Scale22::new(presence_penalty)
                    .expect("Invalid presence penalty"),
            );
            self
        }
    }

    impl AsRef<ChatParams> for ChatParamsWasm {
        fn as_ref(&self) -> &ChatParams {
            &self.0
        }
    }

    impl Deref for ChatParamsWasm {
        type Target = ChatParams;

        fn deref(&self) -> &Self::Target {
            &self.0
        }
    }

    impl DerefMut for ChatParamsWasm {
        fn deref_mut(&mut self) -> &mut Self::Target {
            &mut self.0
        }
    }
}
